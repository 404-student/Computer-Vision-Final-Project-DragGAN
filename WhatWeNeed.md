# 选项1：跟踪鲁棒性
- **上下文：** 论文指出，在无纹理区域中的手柄点有时在跟踪过程中会漂移。
- **任务：** 改进跟踪机制。
  - *想法：* 将简单的最近邻搜索替换为光流估计器 RAFT。
  - *对比：* 在具有挑战性的低纹理场景中，将改进的跟踪器与基准DragGAN跟踪进行比较。

# 选项2：遮罩和背景保留
- **上下文：** DragGAN允许用户绘制二进制遮罩以固定某些区域。
- **任务：** 分析并改进遮罩性能。
  - *想法：* 当前方法在未遮罩区域使用重建损失。尝试将原始图像的特征混合到生成图像中，以更好地保留背景细节，类似于讨论中提到的技术。

# 选项3：DragGAN vs. DragDiffusion
- **上下文：** 虽然DragGAN实现了精确控制，但它受限于底层GAN的领域特异性（例如，训练在人脸模型上的模型不能编辑汽车）。此外，当编辑图像朝向训练期间GAN从未见过的分布外姿势时，DragGAN可能会出现扭曲。
- **替代方案：** DragDiffusion将基于点的交互式编辑框架适应到扩散模型（例如Stable Diffusion），旨在解决通用性问题。
- **任务：**
  1. 部署DragDiffusion：设置并运行*DragDiffusion*的官方实现。
  2. 对比分析：在两种类型的输入上比较DragGAN和DragDiffusion：
    - *领域内：* 完全适合DragGAN训练集的图像（例如，人脸或猫）。比较精度和速度。
    - *开放领域：* 任意图像（例如，雕塑、草图或虚构生物），DragGAN未专门训练过。
  3. 问题解决分析：具体分析和报告：
    - **通用性：** DragDiffusion是否成功编辑了DragGAN因缺乏类别特定训练而失败的图像？
    - **质量：** 比较背景保留。DragGAN有时在复杂背景或无纹理区域上挣扎。扩散模型是否更好地处理这些？